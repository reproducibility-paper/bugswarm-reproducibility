travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: ''
Job id: ''
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
W: The repository 'http://www.apache.org/dist/cassandra/debian 39x Release' does not have a Release file.
W: GPG error: http://dl.google.com/linux/chrome/deb stable InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 4EB27DB2A3B88B8B
W: The repository 'http://dl.google.com/linux/chrome/deb stable InRelease' is not signed.
W: There is no public key available for the following key IDs:
4EB27DB2A3B88B8B  
W: GPG error: http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release: The following signatures were invalid: KEYEXPIRED 1515625755
W: The repository 'http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release' is not signed.
W: The repository 'http://apt.postgresql.org/pub/repos/apt trusty-pgdg Release' does not have a Release file.
W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157
W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
6B05F25D762E3157  
W: The repository 'https://packagecloud.io/basho/riak/ubuntu trusty Release' does not have a Release file.
W: GPG error: https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY F6609E60DC62814E
W: The repository 'https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
F6609E60DC62814E  
W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1)
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-amd64/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-i386/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-amd64/Packages  404  Not Found [IP: 87.238.57.227 80]
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-i386/Packages  404  Not Found [IP: 87.238.57.227 80]
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/source/Sources  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-amd64/Packages  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-i386/Packages  HttpError402
E: Some index files failed to download. They have been ignored, or old ones used instead.
sed: cannot rename /etc/hosts: Device or resource busy
sed: cannot rename /etc/hosts: Device or resource busy
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
$ cd passed/crate/crate-jdbc
travis_fold:start:git.submodule[0Ktravis_time:start:0eff4dc0[0K$ git submodule update --init --recursive

travis_time:end:0eff4dc0:start=1657386414801289926,finish=1657386415513045146,duration=711755220[0Ktravis_fold:end:git.submodule[0K
[33;1mSetting environment variables from .travis.yml[0m
$ export CRATE_VERSION=0.56.4

$ export TERM=dumb
travis_fold:start:cache.1[0KSetting up build cache
$ export CASHER_DIR=$HOME/.casher
travis_time:start:02703382[0K
travis_time:end:02703382:start=1657386416859593487,finish=1657386416867284431,duration=7690944[0Ktravis_time:start:03b0035c[0K/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:65:in `block in fetch'
	from /home/travis/.casher/bin/casher:64:in `each'
	from /home/travis/.casher/bin/casher:64:in `fetch'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'
[32;1mattempting to download cache archive[0m

travis_time:end:03b0035c:start=1657386416877819852,finish=1657386417694780496,duration=816960644[0Ktravis_time:start:2ae8b0d0[0K
travis_time:end:2ae8b0d0:start=1657386417706791677,finish=1657386417719705974,duration=12914297[0Ktravis_time:start:06d0b28b[0K[32;1madding /home/travis/.m2 to cache[0m

travis_time:end:06d0b28b:start=1657386417729631770,finish=1657386421906241464,duration=4176609694[0Ktravis_fold:end:cache.1[0K$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:02b4f238[0K$ JAVA_HOME=$(jdk_switcher home openjdk8) ./gradlew classes testClasses
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE

BUILD SUCCESSFUL in 1m 48s
7 actionable tasks: 1 executed, 6 up-to-date

travis_time:end:02b4f238:start=1657386422181571516,finish=1657386530943719978,duration=108762148462[0Ktravis_fold:end:install[0Ktravis_time:start:291ff714[0K$ ./gradlew test -s
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 2 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:testPicked up _JAVA_OPTIONS: -Xmx2048m -Xms512m


io.crate.client.jdbc.integrationtests.CrateJDBCByPassSpecSettingTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:05,701][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:05,869][INFO ][node                     ] [Mont Mirantin] version[2.3.4], pid[2784], build[${build/NA]
[2022-07-09 17:09:05,869][INFO ][node                     ] [Mont Mirantin] initializing ...
[2022-07-09 17:09:06,139][INFO ][io.crate.plugin          ] [Mont Mirantin] plugins loaded: [crate-sigar] 
[2022-07-09 17:09:07,038][INFO ][plugins                  ] [Mont Mirantin] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:09:07,056][INFO ][env                      ] [Mont Mirantin] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:09:07,056][INFO ][env                      ] [Mont Mirantin] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:09:07,057][WARN ][env                      ] [Mont Mirantin] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:09:07,269][INFO ][http                     ] [Mont Mirantin] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:09:07,280][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_02c51600-da1c-4bfb-a654-4f5ae2183a6e/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:09:07,366][INFO ][io.crate.module          ] [Mont Mirantin] configuring crate. version: 0.56.4
[2022-07-09 17:09:07,551][INFO ][io.crate.module          ] [Mont Mirantin] configuring crate. version: 0.56.4
[2022-07-09 17:09:08,876][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5532]
[2022-07-09 17:09:08,877][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:09:10,117][INFO ][io.crate.rest            ] [Mont Mirantin] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:09:10,167][INFO ][node                     ] [Mont Mirantin] initialized
[2022-07-09 17:09:10,167][INFO ][node                     ] [Mont Mirantin] starting ...
[2022-07-09 17:09:10,320][INFO ][io.crate.blob.BlobService] [Mont Mirantin] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:09:10,444][INFO ][http                     ] [Mont Mirantin] publish_address {127.0.0.1:4585}, bound_addresses {127.0.0.1:4585}
[2022-07-09 17:09:10,512][INFO ][transport                ] [Mont Mirantin] publish_address {127.0.0.1:4398}, bound_addresses {127.0.0.1:4398}
[2022-07-09 17:09:10,520][INFO ][discovery                ] [Mont Mirantin] TestingCluster/8KEpiC2ySXG7QKC2fIls0w
    Stopping crate server process...
[2022-07-09 17:09:11,688][INFO ][node                     ] [Mont Mirantin] stopping ...
[2022-07-09 17:09:11,736][INFO ][node                     ] [Mont Mirantin] stopped
[2022-07-09 17:09:11,736][INFO ][node                     ] [Mont Mirantin] closing ...
[2022-07-09 17:09:11,741][INFO ][node                     ] [Mont Mirantin] closed

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:13,030][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:13,182][INFO ][node                     ] [Pizzo Erra] version[2.3.4], pid[3142], build[${build/NA]
[2022-07-09 17:09:13,182][INFO ][node                     ] [Pizzo Erra] initializing ...
[2022-07-09 17:09:13,485][INFO ][io.crate.plugin          ] [Pizzo Erra] plugins loaded: [crate-sigar] 
[2022-07-09 17:09:14,262][INFO ][plugins                  ] [Pizzo Erra] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:09:14,280][INFO ][env                      ] [Pizzo Erra] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:09:14,281][INFO ][env                      ] [Pizzo Erra] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:09:14,281][WARN ][env                      ] [Pizzo Erra] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:09:14,445][INFO ][http                     ] [Pizzo Erra] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:09:14,454][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_79a00806-0235-4fe1-baad-0e67bcc30897/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:09:14,500][INFO ][io.crate.module          ] [Pizzo Erra] configuring crate. version: 0.56.4
[2022-07-09 17:09:14,690][INFO ][io.crate.module          ] [Pizzo Erra] configuring crate. version: 0.56.4
[2022-07-09 17:09:16,013][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5469]
[2022-07-09 17:09:16,013][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:09:17,266][INFO ][io.crate.rest            ] [Pizzo Erra] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:09:17,321][INFO ][node                     ] [Pizzo Erra] initialized
[2022-07-09 17:09:17,322][INFO ][node                     ] [Pizzo Erra] starting ...
[2022-07-09 17:09:17,483][INFO ][io.crate.blob.BlobService] [Pizzo Erra] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:09:17,626][INFO ][http                     ] [Pizzo Erra] publish_address {127.0.0.1:4529}, bound_addresses {127.0.0.1:4529}
[2022-07-09 17:09:17,714][INFO ][transport                ] [Pizzo Erra] publish_address {127.0.0.1:4289}, bound_addresses {127.0.0.1:4289}
[2022-07-09 17:09:17,723][INFO ][discovery                ] [Pizzo Erra] TestingCluster/qxPlguE6SGCKlWZh2W_WnA
[2022-07-09 17:09:18,258][DEBUG][action.admin.indices.create] [Pizzo Erra] no known master node, scheduling a retry
[2022-07-09 17:09:20,757][INFO ][cluster.service          ] [Pizzo Erra] new_master {Pizzo Erra}{qxPlguE6SGCKlWZh2W_WnA}{127.0.0.1}{127.0.0.1:4289}{info.extended.type=sigar, http_address=127.0.0.1:4529}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-07-09 17:09:20,763][INFO ][node                     ] [Pizzo Erra] started
[2022-07-09 17:09:21,241][INFO ][gateway                  ] [Pizzo Erra] recovered [0] indices into cluster_state
[2022-07-09 17:09:21,431][INFO ][cluster.metadata         ] [Pizzo Erra] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-07-09 17:09:23,295][INFO ][cluster.routing.allocation] [Pizzo Erra] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-07-09 17:09:24,368][DEBUG][action.bulk              ] create new coordinator for node qxPlguE6SGCKlWZh2W_WnA and shard [test][0]
    Stopping crate server process...
[2022-07-09 17:09:25,292][INFO ][node                     ] [Pizzo Erra] stopping ...
[2022-07-09 17:09:26,739][INFO ][node                     ] [Pizzo Erra] stopped
[2022-07-09 17:09:26,739][INFO ][node                     ] [Pizzo Erra] closing ...
[2022-07-09 17:09:26,747][INFO ][node                     ] [Pizzo Erra] closed

io.crate.client.jdbc.integrationtests.CrateJDBCDriverTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:28,069][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:28,200][INFO ][node                     ] [Piz Mundin] version[2.3.4], pid[3534], build[${build/NA]
[2022-07-09 17:09:28,200][INFO ][node                     ] [Piz Mundin] initializing ...
[2022-07-09 17:09:28,464][INFO ][io.crate.plugin          ] [Piz Mundin] plugins loaded: [crate-sigar] 
[2022-07-09 17:09:29,284][INFO ][plugins                  ] [Piz Mundin] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:09:29,305][INFO ][env                      ] [Piz Mundin] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:09:29,306][INFO ][env                      ] [Piz Mundin] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:09:29,306][WARN ][env                      ] [Piz Mundin] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:09:29,511][INFO ][http                     ] [Piz Mundin] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:09:29,521][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_dbee8c14-0047-4308-ba58-46c3d7838b5e/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:09:29,584][INFO ][io.crate.module          ] [Piz Mundin] configuring crate. version: 0.56.4
[2022-07-09 17:09:29,765][INFO ][io.crate.module          ] [Piz Mundin] configuring crate. version: 0.56.4
[2022-07-09 17:09:30,950][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5531]
[2022-07-09 17:09:30,951][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:09:32,260][INFO ][io.crate.rest            ] [Piz Mundin] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:09:32,315][INFO ][node                     ] [Piz Mundin] initialized
[2022-07-09 17:09:32,315][INFO ][node                     ] [Piz Mundin] starting ...
[2022-07-09 17:09:32,570][INFO ][io.crate.blob.BlobService] [Piz Mundin] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:09:32,622][INFO ][http                     ] [Piz Mundin] publish_address {127.0.0.1:4538}, bound_addresses {127.0.0.1:4538}
[2022-07-09 17:09:32,715][INFO ][transport                ] [Piz Mundin] publish_address {127.0.0.1:4290}, bound_addresses {127.0.0.1:4290}
[2022-07-09 17:09:32,721][INFO ][discovery                ] [Piz Mundin] TestingCluster/JnZrczmrT26lZq1iXy-6Yg
    Stopping crate server process...
[2022-07-09 17:09:33,235][INFO ][node                     ] [Piz Mundin] stopping ...
[2022-07-09 17:09:33,303][INFO ][node                     ] [Piz Mundin] stopped
[2022-07-09 17:09:33,303][INFO ][node                     ] [Piz Mundin] closing ...
[2022-07-09 17:09:33,309][INFO ][node                     ] [Piz Mundin] closed

io.crate.client.jdbc.integrationtests.CrateJDBCFetchSizeIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:34,630][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:34,776][INFO ][node                     ] [Cima di Vanerle] version[2.3.4], pid[3891], build[${build/NA]
[2022-07-09 17:09:34,776][INFO ][node                     ] [Cima di Vanerle] initializing ...
[2022-07-09 17:09:35,039][INFO ][io.crate.plugin          ] [Cima di Vanerle] plugins loaded: [crate-sigar] 
[2022-07-09 17:09:35,916][INFO ][plugins                  ] [Cima di Vanerle] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:09:35,939][INFO ][env                      ] [Cima di Vanerle] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:09:35,939][INFO ][env                      ] [Cima di Vanerle] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:09:35,939][WARN ][env                      ] [Cima di Vanerle] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:09:36,152][INFO ][http                     ] [Cima di Vanerle] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:09:36,168][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_5fc4446c-9065-437d-9b29-a13ed33ad32a/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:09:36,229][INFO ][io.crate.module          ] [Cima di Vanerle] configuring crate. version: 0.56.4
[2022-07-09 17:09:36,402][INFO ][io.crate.module          ] [Cima di Vanerle] configuring crate. version: 0.56.4
[2022-07-09 17:09:37,727][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5486]
[2022-07-09 17:09:37,727][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:09:39,103][INFO ][io.crate.rest            ] [Cima di Vanerle] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:09:39,166][INFO ][node                     ] [Cima di Vanerle] initialized
[2022-07-09 17:09:39,167][INFO ][node                     ] [Cima di Vanerle] starting ...
[2022-07-09 17:09:39,335][INFO ][io.crate.blob.BlobService] [Cima di Vanerle] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:09:39,467][INFO ][http                     ] [Cima di Vanerle] publish_address {127.0.0.1:4593}, bound_addresses {127.0.0.1:4593}
[2022-07-09 17:09:39,528][INFO ][transport                ] [Cima di Vanerle] publish_address {127.0.0.1:4349}, bound_addresses {127.0.0.1:4349}
[2022-07-09 17:09:39,533][INFO ][discovery                ] [Cima di Vanerle] TestingCluster/QEJ_WN77Tv-qS4hIa6IVaA
    Stopping crate server process...
[2022-07-09 17:09:39,845][INFO ][node                     ] [Cima di Vanerle] stopping ...
[2022-07-09 17:09:41,066][WARN ][discovery.zen.ping.unicast] [Cima di Vanerle] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:4349}]
SendRequestTransportException[[Cima di Vanerle][127.0.0.1:4349][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-07-09 17:09:41,066][WARN ][discovery.zen.ping.unicast] [Cima di Vanerle] failed to send ping to [{Cima di Vanerle}{QEJ_WN77Tv-qS4hIa6IVaA}{127.0.0.1}{127.0.0.1:4349}{info.extended.type=sigar, http_address=127.0.0.1:4593}]
SendRequestTransportException[[Cima di Vanerle][127.0.0.1:4349][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-07-09 17:09:41,364][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendErrorResponse(Messages.java:231)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:79)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-07-09 17:09:41,365][INFO ][node                     ] [Cima di Vanerle] stopped
[2022-07-09 17:09:41,365][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendReadyForQuery(Messages.java:140)
	at io.crate.protocols.postgres.ConnectionContext$ReadyForQueryListener.onFailure(ConnectionContext.java:222)
	at io.crate.concurrent.CompletionMultiListener.onFailure(CompletionMultiListener.java:63)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:80)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-07-09 17:09:41,365][INFO ][node                     ] [Cima di Vanerle] closing ...
[2022-07-09 17:09:41,372][INFO ][node                     ] [Cima di Vanerle] closed

io.crate.client.jdbc.integrationtests.CrateJDBCMetaDataIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:42,606][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:42,753][INFO ][node                     ] [Les Grandes Aiguilles] version[2.3.4], pid[4252], build[${build/NA]
[2022-07-09 17:09:42,753][INFO ][node                     ] [Les Grandes Aiguilles] initializing ...
[2022-07-09 17:09:43,015][INFO ][io.crate.plugin          ] [Les Grandes Aiguilles] plugins loaded: [crate-sigar] 
[2022-07-09 17:09:44,047][INFO ][plugins                  ] [Les Grandes Aiguilles] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:09:44,066][INFO ][env                      ] [Les Grandes Aiguilles] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:09:44,066][INFO ][env                      ] [Les Grandes Aiguilles] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:09:44,066][WARN ][env                      ] [Les Grandes Aiguilles] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:09:44,297][INFO ][http                     ] [Les Grandes Aiguilles] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:09:44,311][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_dbaf3a53-bcbd-424a-bf49-567bd5d29555/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:09:44,370][INFO ][io.crate.module          ] [Les Grandes Aiguilles] configuring crate. version: 0.56.4
[2022-07-09 17:09:44,567][INFO ][io.crate.module          ] [Les Grandes Aiguilles] configuring crate. version: 0.56.4
[2022-07-09 17:09:45,835][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5458]
[2022-07-09 17:09:45,835][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:09:47,171][INFO ][io.crate.rest            ] [Les Grandes Aiguilles] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:09:47,217][INFO ][node                     ] [Les Grandes Aiguilles] initialized
[2022-07-09 17:09:47,217][INFO ][node                     ] [Les Grandes Aiguilles] starting ...
[2022-07-09 17:09:47,375][INFO ][io.crate.blob.BlobService] [Les Grandes Aiguilles] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:09:47,531][INFO ][http                     ] [Les Grandes Aiguilles] publish_address {127.0.0.1:4519}, bound_addresses {127.0.0.1:4519}
[2022-07-09 17:09:47,684][INFO ][transport                ] [Les Grandes Aiguilles] publish_address {127.0.0.1:4202}, bound_addresses {127.0.0.1:4202}
[2022-07-09 17:09:47,690][INFO ][discovery                ] [Les Grandes Aiguilles] TestingCluster/5TNqnGiCRYuMybQw1ZsvaQ
[2022-07-09 17:09:47,851][DEBUG][action.admin.indices.create] [Les Grandes Aiguilles] no known master node, scheduling a retry
[2022-07-09 17:09:50,720][INFO ][cluster.service          ] [Les Grandes Aiguilles] new_master {Les Grandes Aiguilles}{5TNqnGiCRYuMybQw1ZsvaQ}{127.0.0.1}{127.0.0.1:4202}{info.extended.type=sigar, http_address=127.0.0.1:4519}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-07-09 17:09:50,724][INFO ][node                     ] [Les Grandes Aiguilles] started
[2022-07-09 17:09:52,214][INFO ][gateway                  ] [Les Grandes Aiguilles] recovered [0] indices into cluster_state
[2022-07-09 17:09:52,344][INFO ][cluster.metadata         ] [Les Grandes Aiguilles] [test.cluster] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-07-09 17:09:53,587][INFO ][cluster.routing.allocation] [Les Grandes Aiguilles] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test.cluster][3], [test.cluster][2], [test.cluster][0], [test.cluster][1]] ...]).
[2022-07-09 17:09:53,736][INFO ][cluster.metadata         ] [Les Grandes Aiguilles] [names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-07-09 17:09:55,649][INFO ][cluster.routing.allocation] [Les Grandes Aiguilles] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[names][3], [names][1], [names][0], [names][2]] ...]).
[2022-07-09 17:09:55,774][INFO ][cluster.metadata         ] [Les Grandes Aiguilles] [my_schema.names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-07-09 17:09:56,970][INFO ][cluster.routing.allocation] [Les Grandes Aiguilles] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[my_schema.names][3], [my_schema.names][1], [my_schema.names][2], [my_schema.names][0]] ...]).
[2022-07-09 17:09:57,308][INFO ][cluster.metadata         ] [Les Grandes Aiguilles] [t_multi_pks] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-07-09 17:09:58,286][INFO ][cluster.routing.allocation] [Les Grandes Aiguilles] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[t_multi_pks][1], [t_multi_pks][0], [t_multi_pks][3], [t_multi_pks][2]] ...]).
    Stopping crate server process...
[2022-07-09 17:09:58,418][INFO ][node                     ] [Les Grandes Aiguilles] stopping ...
[2022-07-09 17:09:58,509][INFO ][node                     ] [Les Grandes Aiguilles] stopped
[2022-07-09 17:09:58,509][INFO ][node                     ] [Les Grandes Aiguilles] closing ...
[2022-07-09 17:09:58,518][INFO ][node                     ] [Les Grandes Aiguilles] closed

io.crate.client.jdbc.integrationtests.CrateJDBCTypesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:09:59,733][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:09:59,869][INFO ][node                     ] [Piz Forbesch] version[2.3.4], pid[4656], build[${build/NA]
[2022-07-09 17:09:59,869][INFO ][node                     ] [Piz Forbesch] initializing ...
[2022-07-09 17:10:00,112][INFO ][io.crate.plugin          ] [Piz Forbesch] plugins loaded: [crate-sigar] 
[2022-07-09 17:10:00,984][INFO ][plugins                  ] [Piz Forbesch] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:10:01,004][INFO ][env                      ] [Piz Forbesch] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:10:01,005][INFO ][env                      ] [Piz Forbesch] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:10:01,005][WARN ][env                      ] [Piz Forbesch] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:10:01,184][INFO ][http                     ] [Piz Forbesch] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:10:01,193][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_6f7c63e3-f228-4b75-b44d-7a823b1e93ca/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:10:01,239][INFO ][io.crate.module          ] [Piz Forbesch] configuring crate. version: 0.56.4
[2022-07-09 17:10:01,415][INFO ][io.crate.module          ] [Piz Forbesch] configuring crate. version: 0.56.4
[2022-07-09 17:10:02,573][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5450]
[2022-07-09 17:10:02,574][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:10:03,685][INFO ][io.crate.rest            ] [Piz Forbesch] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:10:03,732][INFO ][node                     ] [Piz Forbesch] initialized
[2022-07-09 17:10:03,732][INFO ][node                     ] [Piz Forbesch] starting ...
[2022-07-09 17:10:03,888][INFO ][io.crate.blob.BlobService] [Piz Forbesch] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:10:03,992][INFO ][http                     ] [Piz Forbesch] publish_address {127.0.0.1:4599}, bound_addresses {127.0.0.1:4599}
[2022-07-09 17:10:04,072][INFO ][transport                ] [Piz Forbesch] publish_address {127.0.0.1:4320}, bound_addresses {127.0.0.1:4320}
[2022-07-09 17:10:04,077][INFO ][discovery                ] [Piz Forbesch] TestingCluster/ikWHYh-NQReBsbgl8IkQqw
[2022-07-09 17:10:04,924][DEBUG][action.admin.indices.create] [Piz Forbesch] no known master node, scheduling a retry
[2022-07-09 17:10:07,114][INFO ][cluster.service          ] [Piz Forbesch] new_master {Piz Forbesch}{ikWHYh-NQReBsbgl8IkQqw}{127.0.0.1}{127.0.0.1:4320}{info.extended.type=sigar, http_address=127.0.0.1:4599}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-07-09 17:10:07,118][INFO ][node                     ] [Piz Forbesch] started
[2022-07-09 17:10:07,288][INFO ][gateway                  ] [Piz Forbesch] recovered [0] indices into cluster_state
[2022-07-09 17:10:07,471][INFO ][cluster.metadata         ] [Piz Forbesch] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-07-09 17:10:07,915][INFO ][cluster.routing.allocation] [Piz Forbesch] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-07-09 17:10:08,818][INFO ][cluster.metadata         ] [Piz Forbesch] [arraytest] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-07-09 17:10:09,931][INFO ][cluster.routing.allocation] [Piz Forbesch] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[arraytest][0]] ...]).
[2022-07-09 17:10:10,274][INFO ][cluster.metadata         ] [Piz Forbesch] [arraytest] update_mapping [default]
[2022-07-09 17:10:10,939][INFO ][cluster.metadata         ] [Piz Forbesch] [test_obj] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-07-09 17:10:11,573][INFO ][cluster.routing.allocation] [Piz Forbesch] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test_obj][3], [test_obj][1], [test_obj][2], [test_obj][0]] ...]).
    Stopping crate server process...
[2022-07-09 17:10:12,109][INFO ][node                     ] [Piz Forbesch] stopping ...
[2022-07-09 17:10:12,941][INFO ][node                     ] [Piz Forbesch] stopped
[2022-07-09 17:10:12,941][INFO ][node                     ] [Piz Forbesch] closing ...
[2022-07-09 17:10:12,950][INFO ][node                     ] [Piz Forbesch] closed

io.crate.client.jdbc.integrationtests.CrateJDBCUnsupportedFeaturesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-07-09 17:10:14,535][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-07-09 17:10:14,665][INFO ][node                     ] [Tiejer Flue] version[2.3.4], pid[5105], build[${build/NA]
[2022-07-09 17:10:14,666][INFO ][node                     ] [Tiejer Flue] initializing ...
[2022-07-09 17:10:14,904][INFO ][io.crate.plugin          ] [Tiejer Flue] plugins loaded: [crate-sigar] 
[2022-07-09 17:10:15,745][INFO ][plugins                  ] [Tiejer Flue] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-07-09 17:10:15,764][INFO ][env                      ] [Tiejer Flue] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.2tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-07-09 17:10:15,764][INFO ][env                      ] [Tiejer Flue] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-07-09 17:10:15,764][WARN ][env                      ] [Tiejer Flue] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-07-09 17:10:15,939][INFO ][http                     ] [Tiejer Flue] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-07-09 17:10:15,948][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_1543fde2-0327-45e0-a66b-375db21cfa15/plugins/elasticsearch-repository-hdfs/
[2022-07-09 17:10:16,001][INFO ][io.crate.module          ] [Tiejer Flue] configuring crate. version: 0.56.4
[2022-07-09 17:10:16,160][INFO ][io.crate.module          ] [Tiejer Flue] configuring crate. version: 0.56.4
[2022-07-09 17:10:17,458][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5530]
[2022-07-09 17:10:17,458][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-07-09 17:10:18,738][INFO ][io.crate.rest            ] [Tiejer Flue] Elasticsearch HTTP REST API not enabled
[2022-07-09 17:10:18,800][INFO ][node                     ] [Tiejer Flue] initialized
[2022-07-09 17:10:18,800][INFO ][node                     ] [Tiejer Flue] starting ...
[2022-07-09 17:10:18,997][INFO ][io.crate.blob.BlobService] [Tiejer Flue] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-07-09 17:10:19,224][INFO ][http                     ] [Tiejer Flue] publish_address {127.0.0.1:4512}, bound_addresses {127.0.0.1:4512}
[2022-07-09 17:10:19,301][INFO ][transport                ] [Tiejer Flue] publish_address {127.0.0.1:4208}, bound_addresses {127.0.0.1:4208}
[2022-07-09 17:10:19,306][INFO ][discovery                ] [Tiejer Flue] TestingCluster/_9y5JOCwRrykbrvrNkIC6g
    Stopping crate server process...
[2022-07-09 17:10:20,504][INFO ][node                     ] [Tiejer Flue] stopping ...
[2022-07-09 17:10:20,582][INFO ][node                     ] [Tiejer Flue] stopped
[2022-07-09 17:10:20,583][INFO ][node                     ] [Tiejer Flue] closing ...
[2022-07-09 17:10:20,590][INFO ][node                     ] [Tiejer Flue] closed
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE
:pg:test SKIPPED

BUILD SUCCESSFUL in 1m 29s
8 actionable tasks: 2 executed, 6 up-to-date

travis_time:end:291ff714:start=1657386530955353744,finish=1657386621387143832,duration=90431790088[0K
[32;1mThe command "./gradlew test -s" exited with 0.[0m
travis_fold:start:cache.2[0Kstore build cache
travis_time:start:07c02154[0K
travis_time:end:07c02154:start=1657386621399039337,finish=1657386621410482041,duration=11442704[0Ktravis_time:start:3aed78b3[0K/home/travis/.casher/bin/casher:190: warning: Insecure world writable dir /usr/local/clang-5.0.0/bin in PATH, mode 040777
[32;1mchanges detected, packing new archive[0m
/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:143:in `push'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'

travis_time:end:3aed78b3:start=1657386621423273004,finish=1657386623320213556,duration=1896940552[0Ktravis_fold:end:cache.2[0K
Done. Your build exited with 0.
