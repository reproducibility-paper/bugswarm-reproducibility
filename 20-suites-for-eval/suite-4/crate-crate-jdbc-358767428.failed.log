travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: ''
Job id: ''
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
W: GPG error: http://dl.google.com/linux/chrome/deb stable InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 78BD65473CB3BD13
W: The repository 'http://dl.google.com/linux/chrome/deb stable InRelease' is not signed.
W: There is no public key available for the following key IDs:
78BD65473CB3BD13  
W: The repository 'http://www.apache.org/dist/cassandra/debian 39x Release' does not have a Release file.
W: The repository 'http://apt.postgresql.org/pub/repos/apt trusty-pgdg Release' does not have a Release file.
W: GPG error: http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release: The following signatures were invalid: KEYEXPIRED 1515625755
W: The repository 'http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release' is not signed.
W: The repository 'https://packagecloud.io/basho/riak/ubuntu trusty Release' does not have a Release file.
W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157
W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
6B05F25D762E3157  
W: GPG error: https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY F6609E60DC62814E
W: The repository 'https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
F6609E60DC62814E  
W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1)
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-amd64/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-i386/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-amd64/Packages  404  Not Found [IP: 72.32.157.246 80]
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-i386/Packages  404  Not Found [IP: 72.32.157.246 80]
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/source/Sources  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-amd64/Packages  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-i386/Packages  HttpError402
E: Some index files failed to download. They have been ignored, or old ones used instead.
sed: cannot rename /etc/hosts: Device or resource busy
sed: cannot rename /etc/hosts: Device or resource busy
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
$ cd failed/crate/crate-jdbc
travis_fold:start:git.submodule[0Ktravis_time:start:00e442ff[0K$ git submodule update --init --recursive

travis_time:end:00e442ff:start=1641078700669485836,finish=1641078701507544957,duration=838059121[0Ktravis_fold:end:git.submodule[0K
[33;1mSetting environment variables from .travis.yml[0m
$ export CRATE_VERSION=0.56.4

$ export TERM=dumb
travis_fold:start:cache.1[0KSetting up build cache
$ export CASHER_DIR=$HOME/.casher
travis_time:start:100411c4[0K
travis_time:end:100411c4:start=1641078704039407053,finish=1641078704049612337,duration=10205284[0Ktravis_time:start:050550ef[0K/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:65:in `block in fetch'
	from /home/travis/.casher/bin/casher:64:in `each'
	from /home/travis/.casher/bin/casher:64:in `fetch'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'
[32;1mattempting to download cache archive[0m

travis_time:end:050550ef:start=1641078704061301302,finish=1641078704923405191,duration=862103889[0Ktravis_time:start:19b8e779[0K
travis_time:end:19b8e779:start=1641078704936975018,finish=1641078704945934493,duration=8959475[0Ktravis_time:start:185f4ee8[0K[32;1madding /home/travis/.m2 to cache[0m

travis_time:end:185f4ee8:start=1641078704958444894,finish=1641078706014663292,duration=1056218398[0Ktravis_fold:end:cache.1[0K$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:00da76cd[0K$ JAVA_HOME=$(jdk_switcher home openjdk8) ./gradlew classes testClasses
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/failed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/failed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE

BUILD SUCCESSFUL in 1m 23s
7 actionable tasks: 1 executed, 6 up-to-date

travis_time:end:00da76cd:start=1641078706290177157,finish=1641078790283833986,duration=83993656829[0Ktravis_fold:end:install[0Ktravis_time:start:116f955e[0K$ ./gradlew test -s
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 2 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/failed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/failed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:testPicked up _JAVA_OPTIONS: -Xmx2048m -Xms512m


io.crate.client.jdbc.integrationtests.CrateJDBCByPassSpecSettingTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:13:25,111][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:13:25,258][INFO ][node                     ] [MÃ¤hrenhorn] version[2.3.4], pid[2781], build[${build/NA]
[2022-01-01 23:13:25,259][INFO ][node                     ] [MÃ¤hrenhorn] initializing ...
[2022-01-01 23:13:25,550][INFO ][io.crate.plugin          ] [MÃ¤hrenhorn] plugins loaded: [crate-sigar] 
[2022-01-01 23:13:26,443][INFO ][plugins                  ] [MÃ¤hrenhorn] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:13:26,470][INFO ][env                      ] [MÃ¤hrenhorn] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:13:26,470][INFO ][env                      ] [MÃ¤hrenhorn] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:13:26,471][WARN ][env                      ] [MÃ¤hrenhorn] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:13:26,687][INFO ][http                     ] [MÃ¤hrenhorn] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:13:26,699][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_2e3678cd-e731-431d-af5f-f6e53a72cd04/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:13:26,778][INFO ][io.crate.module          ] [MÃ¤hrenhorn] configuring crate. version: 0.56.4
[2022-01-01 23:13:26,951][INFO ][io.crate.module          ] [MÃ¤hrenhorn] configuring crate. version: 0.56.4
[2022-01-01 23:13:28,125][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5446]
[2022-01-01 23:13:28,125][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:13:29,333][INFO ][io.crate.rest            ] [MÃ¤hrenhorn] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:13:29,397][INFO ][node                     ] [MÃ¤hrenhorn] initialized
[2022-01-01 23:13:29,397][INFO ][node                     ] [MÃ¤hrenhorn] starting ...
[2022-01-01 23:13:29,583][INFO ][io.crate.blob.BlobService] [MÃ¤hrenhorn] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:13:29,726][INFO ][http                     ] [MÃ¤hrenhorn] publish_address {127.0.0.1:4522}, bound_addresses {127.0.0.1:4522}
[2022-01-01 23:13:29,831][INFO ][transport                ] [MÃ¤hrenhorn] publish_address {127.0.0.1:4258}, bound_addresses {127.0.0.1:4258}
[2022-01-01 23:13:29,838][INFO ][discovery                ] [MÃ¤hrenhorn] TestingCluster/zAbFqbG0SwqgN5mLgaISKw
    Stopping crate server process...
[2022-01-01 23:13:31,056][INFO ][node                     ] [MÃ¤hrenhorn] stopping ...
[2022-01-01 23:13:31,157][INFO ][node                     ] [MÃ¤hrenhorn] stopped
[2022-01-01 23:13:31,157][INFO ][node                     ] [MÃ¤hrenhorn] closing ...
[2022-01-01 23:13:31,166][INFO ][node                     ] [MÃ¤hrenhorn] closed

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:13:32,578][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:13:32,753][INFO ][node                     ] [Les Aiguillettes] version[2.3.4], pid[3139], build[${build/NA]
[2022-01-01 23:13:32,753][INFO ][node                     ] [Les Aiguillettes] initializing ...
[2022-01-01 23:13:33,005][INFO ][io.crate.plugin          ] [Les Aiguillettes] plugins loaded: [crate-sigar] 
[2022-01-01 23:13:33,849][INFO ][plugins                  ] [Les Aiguillettes] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:13:33,866][INFO ][env                      ] [Les Aiguillettes] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:13:33,866][INFO ][env                      ] [Les Aiguillettes] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:13:33,866][WARN ][env                      ] [Les Aiguillettes] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:13:34,029][INFO ][http                     ] [Les Aiguillettes] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:13:34,038][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_0f3a71ef-7b47-4a41-82fd-83f5ec8a9fcc/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:13:34,086][INFO ][io.crate.module          ] [Les Aiguillettes] configuring crate. version: 0.56.4
[2022-01-01 23:13:34,289][INFO ][io.crate.module          ] [Les Aiguillettes] configuring crate. version: 0.56.4
[2022-01-01 23:13:35,540][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5512]
[2022-01-01 23:13:35,540][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:13:36,781][INFO ][io.crate.rest            ] [Les Aiguillettes] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:13:36,840][INFO ][node                     ] [Les Aiguillettes] initialized
[2022-01-01 23:13:36,840][INFO ][node                     ] [Les Aiguillettes] starting ...
[2022-01-01 23:13:37,044][INFO ][io.crate.blob.BlobService] [Les Aiguillettes] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:13:37,118][INFO ][http                     ] [Les Aiguillettes] publish_address {127.0.0.1:4557}, bound_addresses {127.0.0.1:4557}
[2022-01-01 23:13:37,207][INFO ][transport                ] [Les Aiguillettes] publish_address {127.0.0.1:4264}, bound_addresses {127.0.0.1:4264}
[2022-01-01 23:13:37,213][INFO ][discovery                ] [Les Aiguillettes] TestingCluster/xAP59cfaTSGRXYUrEUwXug
[2022-01-01 23:13:37,629][DEBUG][action.admin.indices.create] [Les Aiguillettes] no known master node, scheduling a retry
[2022-01-01 23:13:40,249][INFO ][cluster.service          ] [Les Aiguillettes] new_master {Les Aiguillettes}{xAP59cfaTSGRXYUrEUwXug}{127.0.0.1}{127.0.0.1:4264}{info.extended.type=sigar, http_address=127.0.0.1:4557}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-01 23:13:40,253][INFO ][node                     ] [Les Aiguillettes] started
[2022-01-01 23:13:40,747][INFO ][gateway                  ] [Les Aiguillettes] recovered [0] indices into cluster_state
[2022-01-01 23:13:40,934][INFO ][cluster.metadata         ] [Les Aiguillettes] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-01 23:13:41,687][INFO ][cluster.routing.allocation] [Les Aiguillettes] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-01-01 23:13:42,741][DEBUG][action.bulk              ] create new coordinator for node xAP59cfaTSGRXYUrEUwXug and shard [test][0]

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest > testExecuteBatchPreparedStatementFailBulkTypes FAILED
    java.lang.AssertionError at CrateJDBCConnectionTest.java:284

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest STANDARD_OUT
    Stopping crate server process...
[2022-01-01 23:13:43,913][INFO ][node                     ] [Les Aiguillettes] stopping ...
[2022-01-01 23:13:44,059][INFO ][node                     ] [Les Aiguillettes] stopped
[2022-01-01 23:13:44,059][INFO ][node                     ] [Les Aiguillettes] closing ...
[2022-01-01 23:13:44,069][INFO ][node                     ] [Les Aiguillettes] closed

io.crate.client.jdbc.integrationtests.CrateJDBCDriverTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:13:45,534][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:13:45,671][INFO ][node                     ] [Monte Orsiera] version[2.3.4], pid[3529], build[${build/NA]
[2022-01-01 23:13:45,671][INFO ][node                     ] [Monte Orsiera] initializing ...
[2022-01-01 23:13:45,961][INFO ][io.crate.plugin          ] [Monte Orsiera] plugins loaded: [crate-sigar] 
[2022-01-01 23:13:46,828][INFO ][plugins                  ] [Monte Orsiera] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:13:46,845][INFO ][env                      ] [Monte Orsiera] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:13:46,845][INFO ][env                      ] [Monte Orsiera] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:13:46,845][WARN ][env                      ] [Monte Orsiera] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:13:47,021][INFO ][http                     ] [Monte Orsiera] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:13:47,032][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_87c6bdc6-0e5b-49e5-858f-357f0b43f64d/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:13:47,113][INFO ][io.crate.module          ] [Monte Orsiera] configuring crate. version: 0.56.4
[2022-01-01 23:13:47,314][INFO ][io.crate.module          ] [Monte Orsiera] configuring crate. version: 0.56.4
[2022-01-01 23:13:48,576][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5456]
[2022-01-01 23:13:48,576][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:13:49,726][INFO ][io.crate.rest            ] [Monte Orsiera] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:13:49,771][INFO ][node                     ] [Monte Orsiera] initialized
[2022-01-01 23:13:49,771][INFO ][node                     ] [Monte Orsiera] starting ...
[2022-01-01 23:13:49,926][INFO ][io.crate.blob.BlobService] [Monte Orsiera] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:13:50,046][INFO ][http                     ] [Monte Orsiera] publish_address {127.0.0.1:4571}, bound_addresses {127.0.0.1:4571}
[2022-01-01 23:13:50,112][INFO ][transport                ] [Monte Orsiera] publish_address {127.0.0.1:4332}, bound_addresses {127.0.0.1:4332}
[2022-01-01 23:13:50,119][INFO ][discovery                ] [Monte Orsiera] TestingCluster/TN2Hb0kcS0KtGuiyjeQeKw
    Stopping crate server process...
[2022-01-01 23:13:50,710][INFO ][node                     ] [Monte Orsiera] stopping ...
[2022-01-01 23:13:50,777][INFO ][node                     ] [Monte Orsiera] stopped
[2022-01-01 23:13:50,777][INFO ][node                     ] [Monte Orsiera] closing ...
[2022-01-01 23:13:50,783][INFO ][node                     ] [Monte Orsiera] closed

io.crate.client.jdbc.integrationtests.CrateJDBCFetchSizeIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:13:51,873][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:13:52,009][INFO ][node                     ] [Monte Tinisa] version[2.3.4], pid[3886], build[${build/NA]
[2022-01-01 23:13:52,009][INFO ][node                     ] [Monte Tinisa] initializing ...
[2022-01-01 23:13:52,275][INFO ][io.crate.plugin          ] [Monte Tinisa] plugins loaded: [crate-sigar] 
[2022-01-01 23:13:53,205][INFO ][plugins                  ] [Monte Tinisa] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:13:53,228][INFO ][env                      ] [Monte Tinisa] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:13:53,228][INFO ][env                      ] [Monte Tinisa] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:13:53,228][WARN ][env                      ] [Monte Tinisa] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:13:53,401][INFO ][http                     ] [Monte Tinisa] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:13:53,411][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_aa9641cd-1892-4e43-b27f-0929cc03df1b/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:13:53,492][INFO ][io.crate.module          ] [Monte Tinisa] configuring crate. version: 0.56.4
[2022-01-01 23:13:53,679][INFO ][io.crate.module          ] [Monte Tinisa] configuring crate. version: 0.56.4
[2022-01-01 23:13:55,033][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5444]
[2022-01-01 23:13:55,033][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:13:56,171][INFO ][io.crate.rest            ] [Monte Tinisa] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:13:56,228][INFO ][node                     ] [Monte Tinisa] initialized
[2022-01-01 23:13:56,228][INFO ][node                     ] [Monte Tinisa] starting ...
[2022-01-01 23:13:56,392][INFO ][io.crate.blob.BlobService] [Monte Tinisa] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:13:56,548][INFO ][http                     ] [Monte Tinisa] publish_address {127.0.0.1:4551}, bound_addresses {127.0.0.1:4551}
[2022-01-01 23:13:56,614][INFO ][transport                ] [Monte Tinisa] publish_address {127.0.0.1:4226}, bound_addresses {127.0.0.1:4226}
[2022-01-01 23:13:56,622][INFO ][discovery                ] [Monte Tinisa] TestingCluster/ma6ikVHiSoSEkPxaa7Pkmw
    Stopping crate server process...
[2022-01-01 23:13:57,180][INFO ][node                     ] [Monte Tinisa] stopping ...
[2022-01-01 23:13:58,139][WARN ][discovery.zen.ping.unicast] [Monte Tinisa] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:4226}]
SendRequestTransportException[[Monte Tinisa][127.0.0.1:4226][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-01-01 23:13:58,139][WARN ][discovery.zen.ping.unicast] [Monte Tinisa] failed to send ping to [{Monte Tinisa}{ma6ikVHiSoSEkPxaa7Pkmw}{127.0.0.1}{127.0.0.1:4226}{info.extended.type=sigar, http_address=127.0.0.1:4551}]
SendRequestTransportException[[Monte Tinisa][127.0.0.1:4226][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-01-01 23:13:58,671][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendErrorResponse(Messages.java:231)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:79)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-01-01 23:13:58,672][INFO ][node                     ] [Monte Tinisa] stopped
[2022-01-01 23:13:58,673][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendReadyForQuery(Messages.java:140)
	at io.crate.protocols.postgres.ConnectionContext$ReadyForQueryListener.onFailure(ConnectionContext.java:222)
	at io.crate.concurrent.CompletionMultiListener.onFailure(CompletionMultiListener.java:63)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:80)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-01-01 23:13:58,673][INFO ][node                     ] [Monte Tinisa] closing ...
[2022-01-01 23:13:58,679][INFO ][node                     ] [Monte Tinisa] closed

io.crate.client.jdbc.integrationtests.CrateJDBCMetaDataIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:13:59,965][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:14:00,112][INFO ][node                     ] [Rochers de Naye] version[2.3.4], pid[4248], build[${build/NA]
[2022-01-01 23:14:00,112][INFO ][node                     ] [Rochers de Naye] initializing ...
[2022-01-01 23:14:00,405][INFO ][io.crate.plugin          ] [Rochers de Naye] plugins loaded: [crate-sigar] 
[2022-01-01 23:14:01,263][INFO ][plugins                  ] [Rochers de Naye] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:14:01,282][INFO ][env                      ] [Rochers de Naye] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:14:01,282][INFO ][env                      ] [Rochers de Naye] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:14:01,282][WARN ][env                      ] [Rochers de Naye] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:14:01,470][INFO ][http                     ] [Rochers de Naye] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:14:01,500][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_01eec061-ebff-45c7-b63a-c8cf3489ba23/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:14:01,565][INFO ][io.crate.module          ] [Rochers de Naye] configuring crate. version: 0.56.4
[2022-01-01 23:14:01,759][INFO ][io.crate.module          ] [Rochers de Naye] configuring crate. version: 0.56.4
[2022-01-01 23:14:02,953][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5510]
[2022-01-01 23:14:02,953][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:14:04,129][INFO ][io.crate.rest            ] [Rochers de Naye] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:14:04,181][INFO ][node                     ] [Rochers de Naye] initialized
[2022-01-01 23:14:04,181][INFO ][node                     ] [Rochers de Naye] starting ...
[2022-01-01 23:14:04,355][INFO ][io.crate.blob.BlobService] [Rochers de Naye] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:14:04,490][INFO ][http                     ] [Rochers de Naye] publish_address {127.0.0.1:4584}, bound_addresses {127.0.0.1:4584}
[2022-01-01 23:14:04,603][INFO ][transport                ] [Rochers de Naye] publish_address {127.0.0.1:4249}, bound_addresses {127.0.0.1:4249}
[2022-01-01 23:14:04,611][INFO ][discovery                ] [Rochers de Naye] TestingCluster/AKxJG3M4TKGQ9q6-T7pNag
[2022-01-01 23:14:05,099][DEBUG][action.admin.indices.create] [Rochers de Naye] no known master node, scheduling a retry
[2022-01-01 23:14:07,646][INFO ][cluster.service          ] [Rochers de Naye] new_master {Rochers de Naye}{AKxJG3M4TKGQ9q6-T7pNag}{127.0.0.1}{127.0.0.1:4249}{info.extended.type=sigar, http_address=127.0.0.1:4584}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-01 23:14:07,652][INFO ][node                     ] [Rochers de Naye] started
[2022-01-01 23:14:07,710][INFO ][gateway                  ] [Rochers de Naye] recovered [0] indices into cluster_state
[2022-01-01 23:14:07,874][INFO ][cluster.metadata         ] [Rochers de Naye] [test.cluster] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-01 23:14:08,277][INFO ][cluster.routing.allocation] [Rochers de Naye] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test.cluster][2], [test.cluster][3], [test.cluster][0], [test.cluster][1]] ...]).
[2022-01-01 23:14:08,325][INFO ][cluster.metadata         ] [Rochers de Naye] [names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-01 23:14:08,421][INFO ][cluster.routing.allocation] [Rochers de Naye] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[names][2], [names][3], [names][1], [names][0]] ...]).
[2022-01-01 23:14:08,447][INFO ][cluster.metadata         ] [Rochers de Naye] [my_schema.names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-01 23:14:08,539][INFO ][cluster.routing.allocation] [Rochers de Naye] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[my_schema.names][0], [my_schema.names][0]] ...]).
[2022-01-01 23:14:08,558][INFO ][cluster.metadata         ] [Rochers de Naye] [t_multi_pks] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-01 23:14:08,637][INFO ][cluster.routing.allocation] [Rochers de Naye] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[t_multi_pks][0], [t_multi_pks][0]] ...]).
    Stopping crate server process...
[2022-01-01 23:14:09,058][INFO ][node                     ] [Rochers de Naye] stopping ...
[2022-01-01 23:14:09,172][INFO ][node                     ] [Rochers de Naye] stopped
[2022-01-01 23:14:09,173][INFO ][node                     ] [Rochers de Naye] closing ...
[2022-01-01 23:14:09,181][INFO ][node                     ] [Rochers de Naye] closed

io.crate.client.jdbc.integrationtests.CrateJDBCTypesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:14:10,504][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:14:10,659][INFO ][node                     ] [Piz Medel] version[2.3.4], pid[4651], build[${build/NA]
[2022-01-01 23:14:10,659][INFO ][node                     ] [Piz Medel] initializing ...
[2022-01-01 23:14:10,938][INFO ][io.crate.plugin          ] [Piz Medel] plugins loaded: [crate-sigar] 
[2022-01-01 23:14:11,792][INFO ][plugins                  ] [Piz Medel] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:14:11,814][INFO ][env                      ] [Piz Medel] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:14:11,814][INFO ][env                      ] [Piz Medel] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:14:11,814][WARN ][env                      ] [Piz Medel] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:14:12,012][INFO ][http                     ] [Piz Medel] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:14:12,022][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_bc21a457-4a8b-4240-9b9e-ce23a18a80d1/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:14:12,086][INFO ][io.crate.module          ] [Piz Medel] configuring crate. version: 0.56.4
[2022-01-01 23:14:12,242][INFO ][io.crate.module          ] [Piz Medel] configuring crate. version: 0.56.4
[2022-01-01 23:14:13,458][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5455]
[2022-01-01 23:14:13,458][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:14:14,725][INFO ][io.crate.rest            ] [Piz Medel] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:14:14,780][INFO ][node                     ] [Piz Medel] initialized
[2022-01-01 23:14:14,780][INFO ][node                     ] [Piz Medel] starting ...
[2022-01-01 23:14:14,940][INFO ][io.crate.blob.BlobService] [Piz Medel] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:14:15,063][INFO ][http                     ] [Piz Medel] publish_address {127.0.0.1:4565}, bound_addresses {127.0.0.1:4565}
[2022-01-01 23:14:15,137][INFO ][transport                ] [Piz Medel] publish_address {127.0.0.1:4249}, bound_addresses {127.0.0.1:4249}
[2022-01-01 23:14:15,143][INFO ][discovery                ] [Piz Medel] TestingCluster/yr2yTHOmROGB6XrMkJsQSw
[2022-01-01 23:14:15,642][DEBUG][action.admin.indices.create] [Piz Medel] no known master node, scheduling a retry
[2022-01-01 23:14:18,177][INFO ][cluster.service          ] [Piz Medel] new_master {Piz Medel}{yr2yTHOmROGB6XrMkJsQSw}{127.0.0.1}{127.0.0.1:4249}{info.extended.type=sigar, http_address=127.0.0.1:4565}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-01 23:14:18,182][INFO ][node                     ] [Piz Medel] started
[2022-01-01 23:14:18,220][INFO ][gateway                  ] [Piz Medel] recovered [0] indices into cluster_state
[2022-01-01 23:14:18,439][INFO ][cluster.metadata         ] [Piz Medel] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-01 23:14:18,700][INFO ][cluster.routing.allocation] [Piz Medel] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-01-01 23:14:19,203][INFO ][cluster.metadata         ] [Piz Medel] [arraytest] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-01 23:14:19,242][INFO ][cluster.routing.allocation] [Piz Medel] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[arraytest][0]] ...]).
[2022-01-01 23:14:19,289][INFO ][cluster.metadata         ] [Piz Medel] [arraytest] update_mapping [default]
[2022-01-01 23:14:19,528][INFO ][cluster.metadata         ] [Piz Medel] [test_obj] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-01 23:14:19,593][INFO ][cluster.routing.allocation] [Piz Medel] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test_obj][0], [test_obj][0]] ...]).
    Stopping crate server process...
[2022-01-01 23:14:19,891][INFO ][node                     ] [Piz Medel] stopping ...
[2022-01-01 23:14:19,996][INFO ][node                     ] [Piz Medel] stopped
[2022-01-01 23:14:19,996][INFO ][node                     ] [Piz Medel] closing ...
[2022-01-01 23:14:20,007][INFO ][node                     ] [Piz Medel] closed

io.crate.client.jdbc.integrationtests.CrateJDBCUnsupportedFeaturesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-01 23:14:21,452][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-01 23:14:21,599][INFO ][node                     ] [Corno Baitone] version[2.3.4], pid[5097], build[${build/NA]
[2022-01-01 23:14:21,599][INFO ][node                     ] [Corno Baitone] initializing ...
[2022-01-01 23:14:21,882][INFO ][io.crate.plugin          ] [Corno Baitone] plugins loaded: [crate-sigar] 
[2022-01-01 23:14:22,944][INFO ][plugins                  ] [Corno Baitone] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-01 23:14:22,961][INFO ][env                      ] [Corno Baitone] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-01 23:14:22,961][INFO ][env                      ] [Corno Baitone] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-01 23:14:22,961][WARN ][env                      ] [Corno Baitone] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-01 23:14:23,134][INFO ][http                     ] [Corno Baitone] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-01 23:14:23,145][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_56f4ed77-62f9-4865-8641-36f036b83fb7/plugins/elasticsearch-repository-hdfs/
[2022-01-01 23:14:23,191][INFO ][io.crate.module          ] [Corno Baitone] configuring crate. version: 0.56.4
[2022-01-01 23:14:23,335][INFO ][io.crate.module          ] [Corno Baitone] configuring crate. version: 0.56.4
[2022-01-01 23:14:24,550][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5450]
[2022-01-01 23:14:24,550][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-01 23:14:25,754][INFO ][io.crate.rest            ] [Corno Baitone] Elasticsearch HTTP REST API not enabled
[2022-01-01 23:14:25,860][INFO ][node                     ] [Corno Baitone] initialized
[2022-01-01 23:14:25,860][INFO ][node                     ] [Corno Baitone] starting ...
[2022-01-01 23:14:26,013][INFO ][io.crate.blob.BlobService] [Corno Baitone] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-01 23:14:26,126][INFO ][http                     ] [Corno Baitone] publish_address {127.0.0.1:4597}, bound_addresses {127.0.0.1:4597}
[2022-01-01 23:14:26,248][INFO ][transport                ] [Corno Baitone] publish_address {127.0.0.1:4315}, bound_addresses {127.0.0.1:4315}
[2022-01-01 23:14:26,255][INFO ][discovery                ] [Corno Baitone] TestingCluster/ikpgWlu6SfGSRT5eNh84pw
    Stopping crate server process...
[2022-01-01 23:14:26,602][INFO ][node                     ] [Corno Baitone] stopping ...
[2022-01-01 23:14:26,677][INFO ][node                     ] [Corno Baitone] stopped
[2022-01-01 23:14:26,677][INFO ][node                     ] [Corno Baitone] closing ...
[2022-01-01 23:14:26,686][INFO ][node                     ] [Corno Baitone] closed

92 tests completed, 1 failed, 7 skipped
:test FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':test'.
> There were failing tests. See the report at: file:///home/travis/build/failed/crate/crate-jdbc/build/reports/tests/test/index.html

* Try:
Run with --info or --debug option to get more log output.

* Exception is:
org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:100)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:70)
	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)
	at org.gradle.api.internal.tasks.execution.ResolveTaskOutputCachingStateExecuter.execute(ResolveTaskOutputCachingStateExecuter.java:54)
	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)
	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88)
	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:52)
	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)
	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)
	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)
	at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.run(DefaultTaskGraphExecuter.java:242)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:317)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:309)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:95)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:235)
	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:224)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:121)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:77)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:102)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:96)
	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:612)
	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:567)
	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:96)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)
	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)
Caused by: org.gradle.api.GradleException: There were failing tests. See the report at: file:///home/travis/build/failed/crate/crate-jdbc/build/reports/tests/test/index.html
	at org.gradle.api.tasks.testing.Test.handleTestFailures(Test.java:1411)
	at org.gradle.api.tasks.testing.Test.executeTests(Test.java:702)
	at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.doExecute(DefaultTaskClassInfoStore.java:141)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:134)
	at org.gradle.api.internal.project.taskfactory.DefaultTaskClassInfoStore$StandardTaskAction.execute(DefaultTaskClassInfoStore.java:121)
	at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:711)
	at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:694)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$1.run(ExecuteActionsTaskExecuter.java:122)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:317)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:309)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:185)
	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:95)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:111)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:92)
	... 27 more


BUILD FAILED in 1m 16s
8 actionable tasks: 2 executed, 6 up-to-date

travis_time:end:116f955e:start=1641078790296261367,finish=1641078867370204711,duration=77073943344[0K
[31;1mThe command "./gradlew test -s" exited with 1.[0m
travis_fold:start:cache.2[0Kstore build cache
travis_time:start:020a974c[0K
travis_time:end:020a974c:start=1641078867384545671,finish=1641078867395857859,duration=11312188[0Ktravis_time:start:2df93b89[0K/home/travis/.casher/bin/casher:190: warning: Insecure world writable dir /usr/local/clang-5.0.0/bin in PATH, mode 040777
[32;1mchanges detected, packing new archive[0m
/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:143:in `push'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'

travis_time:end:2df93b89:start=1641078867409238956,finish=1641078869352112263,duration=1942873307[0Ktravis_fold:end:cache.2[0K
Done. Your build exited with 1.
